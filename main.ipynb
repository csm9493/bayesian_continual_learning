{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from core import networks\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for training\n",
    "mini_batch_size = 128\n",
    "lambda_ = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataload (MNIST)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "        batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
    "                       ),\n",
    "        batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom regularization\n",
    "\n",
    "import torch.nn as nn\n",
    "from core.networks import BayesianNetwork\n",
    "def custom_regularization(saver_net, trainer_net,mini_batch_size, lambda_, loss=None):\n",
    "    \n",
    "    mean_reg = 0\n",
    "    sigma_reg = 0\n",
    "    \n",
    "    #net1, net2에서 각 레이어에 있는 mean, sigma를 이용하여 regularization 구현\n",
    "\n",
    "    #각 모델에 module 접근\n",
    "    for saver, trainer in zip(saver_net.modules(),trainer_net.modules()):\n",
    "        \n",
    "        #만약 BayesianNetwork 이면\n",
    "        if isinstance(saver,BayesianNetwork) and  isinstance(trainer,BayesianNetwork):\n",
    "            \n",
    "            #Network 내부의 layer에 순차적으로 접근\n",
    "            for saver_layer, trainer_layer in zip(saver.layer_arr, trainer.layer_arr):\n",
    "            \n",
    "            # calculate mean regularization\n",
    "            \n",
    "                mean_reg += lambda_*(torch.div(trainer_layer.weight_mu, saver_layer.weight_sigma)-torch.div(trainer_layer.weight_mu, trainer_layer.weight_sigma)).norm(2)\n",
    "                \n",
    "                \n",
    "            # calculate sigma_reg regularization\n",
    "            \n",
    "                sigma_reg += torch.sum(torch.div(trainer_layer.weight_sigma, saver_layer.weight_sigma) - torch.log(torch.div(trainer_layer.weight_sigma, saver_layer.weight_sigma)))\n",
    "            \n",
    "            sigma_reg = sigma_reg/(mini_batch_size*2)\n",
    "            mean_reg = mean_reg/(mini_batch_size*2)\n",
    "                \n",
    "#             print (mean_reg, sigma_reg) # regularization value 확인\n",
    "    print ('loss')\n",
    "    print (loss)\n",
    "    print ()\n",
    "#     print ('mean_reg')\n",
    "#     print (mean_reg)\n",
    "#     print ()\n",
    "#     print ('sigma_reg')\n",
    "#     print (sigma_reg)\n",
    "#     print ()\n",
    "    \n",
    "    loss = loss + mean_reg + sigma_reg \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(saver_net,trainer_net, optimizer, epoch, mini_batch_size, lambda_, DEVICE):\n",
    "    trainer_net.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        trainer_net.zero_grad()\n",
    "        loss = trainer_net.sample_elbo(data, target, mini_batch_size, DEVICE) #홍준 코딩\n",
    "        loss = custom_regularization(saver_net, trainer_net, mini_batch_size, lambda_, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "tensor(1.5980e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3020e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1001e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1140e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4299e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1075e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3819e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1357e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5741e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4960e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1365e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6115e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6378e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2260e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1992e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5504e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4725e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3193e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2851e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4057e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4894e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1316e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4707e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2197e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1934e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2953e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1856e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(2.2828e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3680e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3350e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3077e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3348e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2926e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1733e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4462e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.9764e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5939e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5983e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4927e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0824e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1985e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1412e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3968e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4854e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2201e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4410e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2754e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4141e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1404e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3270e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1113e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6948e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3439e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5010e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3761e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3495e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1465e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6669e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1558e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3373e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4869e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3326e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1022e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5454e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6128e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3171e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3407e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4925e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3621e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4080e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99663952., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4674e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1614e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6330e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2137e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96761592., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2557e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1811e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3361e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0603e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4836e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0458e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1697e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3295e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3444e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3920e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1810e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2188e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3856e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4391e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4088e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1360e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2644e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96563464., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3641e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1663e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4684e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3193e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2163e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3155e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3227e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2648e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1318e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2148e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2172e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5391e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0997e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0229e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2169e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96917368., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1000e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4565e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2026e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5419e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2379e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0775e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0770e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4604e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3520e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1066e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1963e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3471e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1926e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3327e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2998e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5803e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0585e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2280e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "tensor(1.0817e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3206e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1867e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4410e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2242e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4076e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2670e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3664e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5156e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1460e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2696e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2581e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2778e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2082e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1821e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1857e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0978e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2495e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2168e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1297e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1394e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3281e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3316e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97304144., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0941e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1982e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1974e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0147e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99395640., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2453e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2837e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4900e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2358e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1473e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98866224., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1024e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94024432., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1103e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2717e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2759e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3506e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3187e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4729e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1496e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1212e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1429e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3840e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4334e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2022e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98171928., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3447e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4543e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1145e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2575e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3207e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2638e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2415e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3057e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1127e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3750e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1200e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1914e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(85583416., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0002e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1480e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0367e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2868e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2674e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1780e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4617e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0536e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0411e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95311616., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3491e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0941e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2294e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3072e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3432e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2731e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3845e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2745e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0356e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5091e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1184e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1633e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95665032., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0387e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0193e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98889544., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0899e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3103e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2542e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1781e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2579e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0631e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1350e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4134e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1265e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1780e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0086e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(84651336., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5087e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1491e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1290e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1382e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2013e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1228e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0581e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2303e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3590e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0529e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3263e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95573560., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3170e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2047e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.5724e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1389e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2302e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1910e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2240e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(88184656., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98735480., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2590e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(89225056., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(85890320., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2798e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1692e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "tensor(1.1247e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95095960., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(93213016., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0723e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4506e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0165e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0240e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0012e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2888e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0022e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97755584., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1978e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1505e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(91543072., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1911e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2499e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1651e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0056e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3103e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0834e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0275e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3256e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98039376., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1656e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0921e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1698e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0578e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2056e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1929e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2010e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(93657528., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0285e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(87655128., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3775e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0586e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95289024., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2158e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2520e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1022e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1151e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(92933320., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3216e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3186e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0422e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2499e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0044e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(87271672., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96278152., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1798e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0678e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(85234320., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3433e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0066e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2920e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2110e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2626e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0882e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0181e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0916e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2047e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2036e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0141e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(88570280., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0962e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2692e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1473e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(88005360., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1361e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94358584., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0122e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0392e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(91447992., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0973e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3706e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1958e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1051e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95608400., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0083e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2287e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97551488., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1177e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1698e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4904e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2971e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0144e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96785840., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95501664., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0036e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2545e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97003440., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4122e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99485656., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1624e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0132e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1340e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1007e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0872e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1244e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1123e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1536e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2537e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99407856., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(89281216., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95711704., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0165e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2284e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.4494e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1136e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0676e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0515e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2501e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2397e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.6882e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0227e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3238e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0564e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0404e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1609e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2469e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2553e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(90724072., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(89777056., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(90937400., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0601e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1473e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1058e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "tensor(1.0832e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99774288., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0898e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99440080., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1089e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0657e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3242e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1608e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1275e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0196e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0382e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(92992344., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0087e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(77828264., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98287632., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99865120., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(80215512., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(86605136., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0518e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3025e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(87184008., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0553e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0083e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2189e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(93010488., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1016e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(80524264., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0497e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3897e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99166600., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0467e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0684e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1319e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2311e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0605e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(93974880., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1395e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0139e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2312e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2797e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(90769776., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(96065952., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1812e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(99439816., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(84630344., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(92294856., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0979e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(84128464., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0176e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(93700240., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0720e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(85513680., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0257e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0771e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1536e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0005e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.3108e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0438e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0196e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1764e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0483e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(81536536., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(77437896., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0161e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94014504., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(92192568., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0192e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94100376., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(91784320., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(92103624., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1949e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97547352., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(95888384., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1379e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94308752., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(94146752., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0158e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0275e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0332e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.2146e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97915184., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(97103512., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.0663e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(86262648., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(98290128., device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1137e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n",
      "loss\n",
      "tensor(1.1775e+08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1]' is invalid for input of size 96",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-23b81911da57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#1. trainet_net training 하는데 regularization을 위해서 saver_net의 정보 이용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#2. 1 batch가 끝나면 saver_net에 trainet_net을 복사 (weight = mean, sigma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f3fa1e4fe94f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(saver_net, trainer_net, optimizer, epoch, mini_batch_size, lambda_, DEVICE)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_elbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#홍준 코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bayesian_continual_learning/core/networks.py\u001b[0m in \u001b[0;36msample_elbo\u001b[0;34m(self, data, target, BATCH_SIZE, DEVICE, samples)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_elbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1]' is invalid for input of size 96"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device_num = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Model Initialization\n",
    "#Saver_Net : mu = 0, sigma = log(1+exp(1))\n",
    "#trainer_ner : mu = [-5,5], sigma = log(1+exp([-5,+5]))\n",
    "saver_net = networks.BayesianNetwork(init_type = 'zero', DEVICE = device_num).to(device_num)\n",
    "trainer_net = networks.BayesianNetwork(init_type = 'random', DEVICE = device_num).to(device_num)\n",
    "\n",
    "optimizer = optim.Adam(saver_net.parameters())\n",
    "optimizer = optim.Adam(trainer_net.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    #0. trainet_net variance init\n",
    "    \n",
    "    trainer_net.variance_init() #trainer net의 variance크게 init\n",
    "    trainer_net = trainer_net.to(device_num)\n",
    "    \n",
    "    #1. trainet_net training 하는데 regularization을 위해서 saver_net의 정보 이용\n",
    "    \n",
    "    train(saver_net, trainer_net, optimizer, epoch, mini_batch_size, lambda_, device_num)\n",
    "\n",
    "    #2. 1 batch가 끝나면 saver_net에 trainet_net을 복사 (weight = mean, sigma)\n",
    "    \n",
    "    saver_net = copy.deepcopy(trainer_net)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
